{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Classifier_class.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### background info: https://towardsdatascience.com/fine-tuning-a-classifier-in-scikit-learn-66e048c21e65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest_Classifier(Classifier):\n",
    "    def run(self, gene_ids):\n",
    "        super().run(gene_ids)\n",
    "        \n",
    "        # Here can go the code to run the SVM classifier itself. For now code it below.\n",
    "        # Output prediction list and true list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a classifier instance\n",
    "c = RandomForest_Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "preselected_ensgs = pd.read_csv('data/preselectedList', names=['ENSG'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function to perform grid search for hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve, auc, make_scorer, f1_score, recall_score, accuracy_score, precision_score, confusion_matrix\n",
    "\n",
    "def grid_search_wrapper(model, train_values, train_labels, test_values, test_labels, refit_score='f1_score'):\n",
    "    \"\"\"\n",
    "    Fit GridSearchCV classifier and print out scores\n",
    "    \"\"\"\n",
    "    param_options = {\n",
    "        'n_estimators' : [8, 9, 10, 11, 12, 13],\n",
    "        'max_depth': [2, 3, 7],\n",
    "        'min_samples_split': [2, 3],\n",
    "        'max_features': [None, 'sqrt', 'log2']\n",
    "    }\n",
    "    \n",
    "\n",
    "    score_options = {\n",
    "        'precision_score': make_scorer(precision_score),\n",
    "        'recall_score': make_scorer(recall_score),\n",
    "        'f1_score': make_scorer(f1_score),\n",
    "        \n",
    "    }\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=3)\n",
    "    grid_search = GridSearchCV(model, param_options, scoring=score_options, refit=refit_score,\n",
    "                           cv=skf, return_train_score=True, n_jobs=-1)\n",
    "    grid_search.fit(train_values, train_labels)\n",
    "\n",
    "    # make the predictions\n",
    "    predicted_test_labels = grid_search.predict(test_values)\n",
    "\n",
    "    print('Best params for {}'.format(refit_score))\n",
    "    print(grid_search.best_params_)\n",
    "\n",
    "    # confusion matrix on the test data.\n",
    "    print('\\nConfusion matrix of Random Forest optimized for {} on the test data:'.format(refit_score))\n",
    "    print(test_labels)\n",
    "    print(predicted_test_labels)\n",
    "    print(pd.DataFrame(confusion_matrix(test_labels, predicted_test_labels),\n",
    "                 columns=['pred_neg', 'pred_pos'], index=['neg', 'pos']))\n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform grid search to optimize hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running classifier with 60675 genes...\n",
      "\t57 examles in training set\n",
      "\t39 examples in test set\n",
      "\t0.2982456140350877: fraction of positives in training set\n",
      "\t0.28205128205128205: fraction of positives in test set\n",
      "Best params for f1_score\n",
      "{'max_depth': 3, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 8}\n",
      "\n",
      "Confusion matrix of Random Forest optimized for f1_score on the test data:\n",
      "[0 0 0 1 0 0 0 0 0 1 0 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 1\n",
      " 0 0]\n",
      "[0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0]\n",
      "     pred_neg  pred_pos\n",
      "neg        27         1\n",
      "pos         8         3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erickofman/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "# Random seed for reproducibility\n",
    "SEED = 10\n",
    "\n",
    "c.run(None)\n",
    "#c.run(list(preselected_ensgs.ENSG))\n",
    "\n",
    "# most important 72 features when using 12 estimators and sqrt max features\n",
    "max_features = ['ENSG00000114346', 'ENSG00000160255', 'ENSG00000085832', 'ENSG00000003756', 'ENSG00000174371', \n",
    "       'ENSG00000112130', 'ENSG00000120708', 'ENSG00000106305', 'ENSG00000160094', 'ENSG00000173898',\n",
    "       'ENSG00000197019', 'ENSG00000089157', 'ENSG00000241697', 'ENSG00000039068', 'ENSG00000087253',\n",
    "       'ENSG00000184363', 'ENSG00000168646', 'ENSG00000100197', 'ENSG00000139687', 'ENSG00000239672', \n",
    "       'ENSG00000101935', 'ENSG00000104205', 'ENSG00000124920', 'ENSG00000150403', 'ENSG00000144354', \n",
    "       'ENSG00000133884', 'ENSG00000148248', 'ENSG00000084207', 'ENSG00000166482', 'ENSG00000129625', \n",
    "       'ENSG00000133789', 'ENSG00000158717', 'ENSG00000177508', 'ENSG00000187790', 'ENSG00000185432', \n",
    "       'ENSG00000076003', 'ENSG00000163156', 'ENSG00000164161', 'ENSG00000112977', 'ENSG00000121879', \n",
    "       'ENSG00000134333', 'ENSG00000215252', 'ENSG00000145715', 'ENSG00000178999', 'ENSG00000170502', \n",
    "       'ENSG00000136738', 'ENSG00000145335', 'ENSG00000099622', 'ENSG00000198815', 'ENSG00000151693', \n",
    "       'ENSG00000100298', 'ENSG00000107262', 'ENSG00000148935', 'ENSG00000047849', 'ENSG00000168874', \n",
    "       'ENSG00000166483', 'ENSG00000169136', 'ENSG00000146648', 'ENSG00000150401', 'ENSG00000154229',\n",
    "       'ENSG00000158270', 'ENSG00000171552', 'ENSG00000102753', 'ENSG00000166579', 'ENSG00000094804',\n",
    "       'ENSG00000127252', 'ENSG00000113810', 'ENSG00000066697', 'ENSG00000125414', 'ENSG00000112715',\n",
    "       'ENSG00000184182']\n",
    "#c.run(max_features)\n",
    "\n",
    "\n",
    "def run_override(data, parameters=None):\n",
    "    # Code the SVM classification process here for now, so that you don't have to reinstantiate the classifier \n",
    "    # (block above) every time you make a change. Parameters are optional, no need to include them until fine-tuning\n",
    "    # probably.\n",
    "    \n",
    "    # Extract the labels\n",
    "    labels = np.array(c.subsetted_tpm.index.get_level_values(1))\n",
    "\n",
    "    # Set aside test data\n",
    "    train, test, train_labels, test_labels = train_test_split(data, \n",
    "                                                              labels, \n",
    "                                                              stratify = labels,\n",
    "                                                              test_size=0.4,\n",
    "                                                              random_state = SEED)\n",
    "\n",
    "    print('\\t{} examles in training set'.format(len(train)))\n",
    "    print('\\t{} examples in test set'.format(len(test)))\n",
    "    \n",
    "    print('\\t{}: fraction of positives in training set'.format(\n",
    "        sum(train.index.get_level_values(1))/len(train.index.get_level_values(1))))\n",
    "    print('\\t{}: fraction of positives in test set'.format(\n",
    "        sum(test.index.get_level_values(1))/len(test.index.get_level_values(1))))\n",
    "\n",
    "    # Make a model\n",
    "    model = RandomForestClassifier(\n",
    "        #n_estimators=12, \n",
    "        random_state=SEED, \n",
    "        #max_features = 'sqrt',\n",
    "    )\n",
    "\n",
    "    return grid_search_wrapper(model, train, train_labels, test, test_labels)\n",
    "    \n",
    "grid_search_results = run_override(c.subsetted_tpm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The recall is the ratio tp / (tp + fn)\n",
    "# The precision is ratio tp / (tp + fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_precision_score</th>\n",
       "      <th>mean_test_recall_score</th>\n",
       "      <th>mean_test_f1_score</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.342</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.276</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>log2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.342</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.276</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>log2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.412</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.244</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.386</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.242</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.442</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.252</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_test_precision_score  mean_test_recall_score  mean_test_f1_score  \\\n",
       "60                      0.342                   0.233               0.276   \n",
       "66                      0.342                   0.233               0.276   \n",
       "55                      0.412                   0.177               0.244   \n",
       "20                      0.386                   0.177               0.242   \n",
       "19                      0.442                   0.177               0.252   \n",
       "\n",
       "   param_min_samples_split param_max_depth param_max_features  \\\n",
       "60                       2               3               log2   \n",
       "66                       3               3               log2   \n",
       "55                       3               3               sqrt   \n",
       "20                       3               2               sqrt   \n",
       "19                       3               2               sqrt   \n",
       "\n",
       "   param_n_estimators  \n",
       "60                  8  \n",
       "66                  8  \n",
       "55                  9  \n",
       "20                 10  \n",
       "19                  9  "
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "results = pd.DataFrame(grid_search_results.cv_results_)\n",
    "results = results.sort_values(by='mean_test_recall_score', ascending=False)\n",
    "results[['mean_test_precision_score', 'mean_test_recall_score', 'mean_test_f1_score', 'param_min_samples_split', 'param_max_depth', 'param_max_features', 'param_n_estimators']].round(3).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running classifier with 60675 genes...\n",
      "\t67 examles in training set\n",
      "\t29 examples in test set\n",
      "\t0.29850746268656714: fraction of positives in training set\n",
      "\t0.27586206896551724: fraction of positives in test set\n",
      "[0.1907483  0.36111954 0.29870284 0.37309466 0.43887579 0.43061316\n",
      " 0.45642718 0.5998929  0.5236244  0.39206651 0.27560581 0.29140862\n",
      " 0.29133548 0.29382071 0.3981387  0.23295231 0.20340928 0.52219909\n",
      " 0.50708589 0.63208085 0.52677526 0.62149154 0.60411683 0.331428\n",
      " 0.37100872 0.77741228 0.26727503 0.60846149 0.30154375]\n",
      "0.7261904761904763\n",
      "     pred_neg  pred_pos\n",
      "neg        15         6\n",
      "pos         4         4\n",
      "Threshold of 0.1\n",
      "     pred_neg  pred_pos\n",
      "neg         0        21\n",
      "pos         0         8\n",
      "Threshold of 0.2\n",
      "     pred_neg  pred_pos\n",
      "neg         1        20\n",
      "pos         0         8\n",
      "Threshold of 0.3\n",
      "     pred_neg  pred_pos\n",
      "neg         8        13\n",
      "pos         1         7\n",
      "Threshold of 0.4\n",
      "     pred_neg  pred_pos\n",
      "neg        14         7\n",
      "pos         2         6\n",
      "Threshold of 0.5\n",
      "     pred_neg  pred_pos\n",
      "neg        15         6\n",
      "pos         4         4\n",
      "Threshold of 0.6\n",
      "     pred_neg  pred_pos\n",
      "neg        19         2\n",
      "pos         5         3\n",
      "Threshold of 0.7\n",
      "     pred_neg  pred_pos\n",
      "neg        20         1\n",
      "pos         8         0\n",
      "Threshold of 0.8\n",
      "     pred_neg  pred_pos\n",
      "neg        21         0\n",
      "pos         8         0\n",
      "Threshold of 0.9\n",
      "     pred_neg  pred_pos\n",
      "neg        21         0\n",
      "pos         8         0\n",
      "                             feature  importance\n",
      "57967  (ENSG00000278531, AL512324.3)    0.056006\n",
      "7166        (ENSG00000135870, RC3H1)    0.050438\n",
      "1190       (ENSG00000072401, UBE2D1)    0.043987\n",
      "51615  (ENSG00000267651, AC015961.1)    0.042907\n",
      "10550      (ENSG00000160868, CYP3A4)    0.042138\n",
      "32868  (ENSG00000234182, AL731533.1)    0.040857\n",
      "34657  (ENSG00000236800, AC068898.1)    0.039974\n",
      "12349   (ENSG00000168367, LINC00917)    0.039123\n",
      "1527         (ENSG00000081154, PCNP)    0.036475\n",
      "8259       (ENSG00000142611, PRDM16)    0.034676\n",
      "52845  (ENSG00000270593, AC073333.2)    0.033471\n",
      "49282  (ENSG00000264269, AC016866.1)    0.033469\n",
      "29824       (ENSG00000229829, DUTP4)    0.033125\n",
      "30682  (ENSG00000231032, AC114814.2)    0.032515\n",
      "9941        (ENSG00000156049, GNA14)    0.026978\n",
      "34396  (ENSG00000236426, AL583824.1)    0.025803\n",
      "16683     (ENSG00000188186, LAMTOR4)    0.025444\n",
      "53002  (ENSG00000270839, AC091393.1)    0.025355\n",
      "17094      (ENSG00000196313, POM121)    0.025186\n",
      "10710       (ENSG00000162341, TPCN2)    0.024778\n",
      "4900         (ENSG00000119408, NEK6)    0.022983\n",
      "24701        (ENSG00000221818, EBF2)    0.022738\n",
      "11613       (ENSG00000165490, DDIAS)    0.022468\n",
      "59002  (ENSG00000279755, AC091905.3)    0.020641\n",
      "43792   (ENSG00000255109, LINC02740)    0.020604\n",
      "33854   (ENSG00000235621, LINC00494)    0.018729\n",
      "34907   (ENSG00000237166, LINC01792)    0.018623\n",
      "35255     (ENSG00000237642, HMGB3P5)    0.018608\n",
      "28265      (ENSG00000227500, SCAMP4)    0.014061\n",
      "16420     (ENSG00000187048, CYP4A11)    0.012381\n",
      "...                              ...         ...\n",
      "20247         (ENSG00000205403, CFI)    0.000000\n",
      "20246   (ENSG00000205396, LINC00661)    0.000000\n",
      "20245        (ENSG00000205364, MT1M)    0.000000\n",
      "20244      (ENSG00000205363, INSYN1)    0.000000\n",
      "20219  (ENSG00000205300, AL356414.1)    0.000000\n",
      "20220      (ENSG00000205301, MGAT4D)    0.000000\n",
      "20221        (ENSG00000205302, SNX2)    0.000000\n",
      "20222       (ENSG00000205307, SAP25)    0.000000\n",
      "20223        (ENSG00000205309, NT5M)    0.000000\n",
      "20224     (ENSG00000205312, KRT17P4)    0.000000\n",
      "20225     (ENSG00000205318, GCNT2P1)    0.000000\n",
      "20226       (ENSG00000205323, SARNP)    0.000000\n",
      "20227  (ENSG00000205325, AC005863.1)    0.000000\n",
      "20228      (ENSG00000205327, OR6C68)    0.000000\n",
      "20229      (ENSG00000205328, OR6C65)    0.000000\n",
      "20230       (ENSG00000205329, OR6C3)    0.000000\n",
      "20231       (ENSG00000205330, OR6C1)    0.000000\n",
      "20232     (ENSG00000205331, OR6C72P)    0.000000\n",
      "20233    (ENSG00000205333, GOLGA2P1)    0.000000\n",
      "20234   (ENSG00000205334, LINC01460)    0.000000\n",
      "20235      (ENSG00000205336, ADGRG1)    0.000000\n",
      "20236        (ENSG00000205339, IPO7)    0.000000\n",
      "20237       (ENSG00000205352, PRR13)    0.000000\n",
      "20238      (ENSG00000205356, TECPR1)    0.000000\n",
      "20239        (ENSG00000205358, MT1H)    0.000000\n",
      "20240     (ENSG00000205359, SLCO6A1)    0.000000\n",
      "20241       (ENSG00000205360, MT1CP)    0.000000\n",
      "20242       (ENSG00000205361, MT1DP)    0.000000\n",
      "20243        (ENSG00000205362, MT1A)    0.000000\n",
      "60674  (ENSG00000283125, AC022726.2)    0.000000\n",
      "\n",
      "[60675 rows x 2 columns]\n",
      "['ENSG00000135870', 'ENSG00000072401', 'ENSG00000267651', 'ENSG00000160868', 'ENSG00000234182', 'ENSG00000236800', 'ENSG00000168367', 'ENSG00000081154', 'ENSG00000142611', 'ENSG00000270593', 'ENSG00000264269', 'ENSG00000229829', 'ENSG00000231032', 'ENSG00000156049', 'ENSG00000236426', 'ENSG00000188186', 'ENSG00000270839', 'ENSG00000196313', 'ENSG00000162341', 'ENSG00000119408', 'ENSG00000221818', 'ENSG00000165490', 'ENSG00000279755', 'ENSG00000255109', 'ENSG00000235621', 'ENSG00000237166', 'ENSG00000237642', 'ENSG00000227500', 'ENSG00000187048', 'ENSG00000241552', 'ENSG00000233108', 'ENSG00000255679', 'ENSG00000145220', 'ENSG00000074054', 'ENSG00000178425', 'ENSG00000261347', 'ENSG00000178836', 'ENSG00000006695', 'ENSG00000219619', 'ENSG00000124713', 'ENSG00000250903', 'ENSG00000250905', 'ENSG00000250906', 'ENSG00000250908', 'ENSG00000250909', 'ENSG00000250910', 'ENSG00000250929', 'ENSG00000250913', 'ENSG00000250914', 'ENSG00000250928', 'ENSG00000251009', 'ENSG00000250927', 'ENSG00000250917', 'ENSG00000250902', 'ENSG00000250919', 'ENSG00000251008', 'ENSG00000250920', 'ENSG00000251005', 'ENSG00000250921', 'ENSG00000250922', 'ENSG00000250923', 'ENSG00000250915', 'ENSG00000250986', 'ENSG00000250900', 'ENSG00000250891', 'ENSG00000250884', 'ENSG00000251014', 'ENSG00000250885', 'ENSG00000250886', 'ENSG00000250887', 'ENSG00000250888']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve, auc, make_scorer, recall_score, accuracy_score, precision_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "# Random seed for reproducibility\n",
    "SEED = 12\n",
    "\n",
    "#c.run(list(preselected_ensgs.ENSG))\n",
    "c.run(None)\n",
    "\n",
    "def run_override_using_optimal(data, parameters=None):\n",
    "    # Code the SVM classification process here for now, so that you don't have to reinstantiate the classifier \n",
    "    # (block above) every time you make a change. Parameters are optional, no need to include them until fine-tuning\n",
    "    # probably.\n",
    "    \n",
    "    # Extract the labels\n",
    "    labels = np.array(c.subsetted_tpm.index.get_level_values(1))\n",
    "\n",
    "    # Set aside test data\n",
    "    train, test, train_labels, test_labels = train_test_split(data, \n",
    "                                                              labels, \n",
    "                                                              stratify = labels,\n",
    "                                                              test_size=0.3,\n",
    "                                                              random_state = SEED)\n",
    "\n",
    "    print('\\t{} examles in training set'.format(len(train)))\n",
    "    print('\\t{} examples in test set'.format(len(test)))\n",
    "    \n",
    "    print('\\t{}: fraction of positives in training set'.format(\n",
    "        sum(train.index.get_level_values(1))/len(train.index.get_level_values(1))))\n",
    "    print('\\t{}: fraction of positives in test set'.format(\n",
    "        sum(test.index.get_level_values(1))/len(test.index.get_level_values(1))))\n",
    "\n",
    "    # Make a model\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=8, \n",
    "        random_state=SEED, \n",
    "        max_features = 'log2',\n",
    "        max_depth = 3,\n",
    "        min_samples_split = 2\n",
    "    )\n",
    "\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(train, train_labels)\n",
    "\n",
    "    # Guesses\n",
    "    guesses = model.predict(test)\n",
    "    \n",
    "    # Probabilities per class\n",
    "    probs = model.predict_proba(test)[:, 1]\n",
    "    print(probs)\n",
    "    \n",
    "    \n",
    "    roc_value = roc_auc_score(test_labels, probs)\n",
    "    print(roc_value)\n",
    "    \n",
    "    print(pd.DataFrame(confusion_matrix(test_labels, guesses),\n",
    "                 columns=['pred_neg', 'pred_pos'], index=['neg', 'pos']))\n",
    "    \n",
    "    # Adjusted\n",
    "    for threshold in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]:\n",
    "        print('Threshold of {}'.format(threshold))\n",
    "        adjusted_guesses = [1 if p >= threshold else 0 for p in probs]\n",
    "        print(pd.DataFrame(confusion_matrix(test_labels, adjusted_guesses),\n",
    "                 columns=['pred_neg', 'pred_pos'], index=['neg', 'pos']))\n",
    "\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': list(train.columns),\n",
    "        'importance': model.feature_importances_}).\\\n",
    "    sort_values('importance', ascending = False)\n",
    "    print(feature_importance)\n",
    "    \n",
    "    most_important_ensgs = [i[0] for i in  list(feature_importance[1:72].feature)]\n",
    "    print(most_important_ensgs)\n",
    "    \n",
    "run_override_using_optimal(c.subsetted_tpm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
