{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import copy\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataset = pd.read_csv('data/cancer_tpm_multiindexed.tsv', sep='\\t', index_col=[0,1], header=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use only ENSG column IDs\n",
    "original_dataset.columns = list(original_dataset.columns.get_level_values(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set output column as recurrence\n",
    "output_col = original_dataset.index.get_level_values(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set index just to sample ID\n",
    "original_dataset.index = list(original_dataset.index.get_level_values(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data????\n",
    "norm = (original_dataset.loc['C1'] - original_dataset.loc['C1'].mean()).divide(original_dataset.loc['C1'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the output label\n",
    "original_dataset['output'] = output_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(original_dataset[original_dataset.output == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENSG00000000003</th>\n",
       "      <th>ENSG00000000005</th>\n",
       "      <th>ENSG00000000419</th>\n",
       "      <th>ENSG00000000457</th>\n",
       "      <th>ENSG00000000460</th>\n",
       "      <th>ENSG00000000938</th>\n",
       "      <th>ENSG00000000971</th>\n",
       "      <th>ENSG00000001036</th>\n",
       "      <th>ENSG00000001084</th>\n",
       "      <th>ENSG00000001167</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSG00000283101</th>\n",
       "      <th>ENSG00000283103</th>\n",
       "      <th>ENSG00000283108</th>\n",
       "      <th>ENSG00000283110</th>\n",
       "      <th>ENSG00000283117</th>\n",
       "      <th>ENSG00000283118</th>\n",
       "      <th>ENSG00000283122</th>\n",
       "      <th>ENSG00000283123</th>\n",
       "      <th>ENSG00000283125</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C1</th>\n",
       "      <td>7.071605</td>\n",
       "      <td>13.279391</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.212355</td>\n",
       "      <td>34.038592</td>\n",
       "      <td>9.231355</td>\n",
       "      <td>32.811263</td>\n",
       "      <td>19.136966</td>\n",
       "      <td>12.631348</td>\n",
       "      <td>11.220057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.430132</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.856902</td>\n",
       "      <td>16.599238</td>\n",
       "      <td>22.357146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.542796</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C2</th>\n",
       "      <td>60.610797</td>\n",
       "      <td>47.424080</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.218590</td>\n",
       "      <td>35.828348</td>\n",
       "      <td>4.395669</td>\n",
       "      <td>22.498053</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.413170</td>\n",
       "      <td>48.083612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48.996429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.795095</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.562460</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C3</th>\n",
       "      <td>58.255903</td>\n",
       "      <td>60.455497</td>\n",
       "      <td>23.040206</td>\n",
       "      <td>12.120963</td>\n",
       "      <td>55.926653</td>\n",
       "      <td>8.005046</td>\n",
       "      <td>13.657227</td>\n",
       "      <td>14.935300</td>\n",
       "      <td>16.430065</td>\n",
       "      <td>14.594347</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.871406</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.378542</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.463189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C4</th>\n",
       "      <td>29.917356</td>\n",
       "      <td>6.482332</td>\n",
       "      <td>8.646690</td>\n",
       "      <td>6.065120</td>\n",
       "      <td>10.494273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.064209</td>\n",
       "      <td>18.683413</td>\n",
       "      <td>9.865584</td>\n",
       "      <td>8.215603</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.486271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.388781</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.236364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C5</th>\n",
       "      <td>24.500322</td>\n",
       "      <td>53.675826</td>\n",
       "      <td>20.456404</td>\n",
       "      <td>16.142519</td>\n",
       "      <td>14.482668</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>59.112604</td>\n",
       "      <td>8.840272</td>\n",
       "      <td>55.432674</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.407358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.797049</td>\n",
       "      <td>57.509813</td>\n",
       "      <td>3.688509</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.138720</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 60676 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ENSG00000000003  ENSG00000000005  ENSG00000000419  ENSG00000000457  \\\n",
       "C1         7.071605        13.279391         0.000000         6.212355   \n",
       "C2        60.610797        47.424080         0.000000         2.218590   \n",
       "C3        58.255903        60.455497        23.040206        12.120963   \n",
       "C4        29.917356         6.482332         8.646690         6.065120   \n",
       "C5        24.500322        53.675826        20.456404        16.142519   \n",
       "\n",
       "    ENSG00000000460  ENSG00000000938  ENSG00000000971  ENSG00000001036  \\\n",
       "C1        34.038592         9.231355        32.811263        19.136966   \n",
       "C2        35.828348         4.395669        22.498053         0.000000   \n",
       "C3        55.926653         8.005046        13.657227        14.935300   \n",
       "C4        10.494273         0.000000        23.064209        18.683413   \n",
       "C5        14.482668         0.000000        59.112604         8.840272   \n",
       "\n",
       "    ENSG00000001084  ENSG00000001167  ...  ENSG00000283101  ENSG00000283103  \\\n",
       "C1        12.631348        11.220057  ...              0.0         4.430132   \n",
       "C2         5.413170        48.083612  ...              0.0         0.000000   \n",
       "C3        16.430065        14.594347  ...              0.0         0.000000   \n",
       "C4         9.865584         8.215603  ...              0.0         0.000000   \n",
       "C5        55.432674         0.000000  ...              0.0         0.000000   \n",
       "\n",
       "    ENSG00000283108  ENSG00000283110  ENSG00000283117  ENSG00000283118  \\\n",
       "C1         0.000000              0.0         6.856902        16.599238   \n",
       "C2        48.996429              0.0         9.795095         0.000000   \n",
       "C3        14.871406              0.0        13.378542         0.000000   \n",
       "C4        33.486271              0.0        13.388781         0.000000   \n",
       "C5        26.407358              0.0        19.797049        57.509813   \n",
       "\n",
       "    ENSG00000283122  ENSG00000283123  ENSG00000283125  output  \n",
       "C1        22.357146              0.0        19.542796       1  \n",
       "C2         4.562460              0.0         0.000000       1  \n",
       "C3        12.463189              0.0         0.000000       1  \n",
       "C4         6.236364              0.0         0.000000       1  \n",
       "C5         3.688509              0.0        45.138720       1  \n",
       "\n",
       "[5 rows x 60676 columns]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final dataset to do build the neural net.\n",
    "original_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_750_expressed_genes = list(original_dataset.mean().sort_values(ascending=False).head(750).index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model construction based heavily on: https://github.com/philipobrien/colab-notebooks/blob/master/Non_Linear_Data_Classification.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "preselected_ensgs = pd.read_csv('data/preselectedList', names=['ENSG'])\n",
    "ensgs_subset = list(preselected_ensgs['ENSG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "sns.set()\n",
    "\n",
    "# This never changes...\n",
    "MANUAL_SEED = 2\n",
    "torch.manual_seed(MANUAL_SEED)\n",
    "\n",
    "# Model methods definition \n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, H1, output_size):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_size, H1)\n",
    "        self.linear2 = nn.Linear(H1, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.linear(x))\n",
    "        x = torch.sigmoid(self.linear2(x))\n",
    "        return x\n",
    "    \n",
    "    def predict(self, x):\n",
    "        pred = self.forward(x)\n",
    "        return pred\n",
    "\n",
    "# Split the datase for cross-validation purposes, 2/3 training, 1/3 testing\n",
    "def split_dataset(original_dataset, fraction_test, random_seed, num_features=1000):\n",
    "    train, test, train_labels, test_labels = train_test_split(original_dataset, \n",
    "                                                              output_col, \n",
    "                                                              stratify = output_col,\n",
    "                                                              test_size=fraction_test,\n",
    "                                                              random_state = SPLIT_SEED)\n",
    "    \n",
    "    #print('columns used: {}'.format(train.columns))\n",
    "    \n",
    "    print('Using only the first {} genes...'.format(num_features))\n",
    "    X = np.array(train[train.columns[0:num_features]])\n",
    "    y = np.array(train.output)\n",
    "\n",
    "    # Tensorify the input and output arrays\n",
    "    x_data = torch.FloatTensor(X)\n",
    "    y_data = torch.FloatTensor(y.reshape(len(y), 1))\n",
    "    return x_data, y_data, train_labels, test, test_labels\n",
    "\n",
    "# Loss function information: \n",
    "# https://medium.com/udacity-pytorch-challengers/a-brief-overview-of-loss-functions-in-pytorch-c0ddb78068f7\n",
    "def run_model(x_data, y_data, test, num_features, hidden_layer_size=4, learning_rate=0.0001, epochs=5000):\n",
    "    model = Model(num_features, hidden_layer_size, 1)\n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    losses = []\n",
    "    for i in range(epochs):\n",
    "        # Make predictions based on current weights in model\n",
    "        y_pred = model.forward(x_data)\n",
    "\n",
    "        # Calculate new loss\n",
    "        loss = criterion(y_pred, y_data)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        if i%10000==0:\n",
    "            print(f\"epoch: {i}, loss: {loss.item()}\")\n",
    "\n",
    "        # Calculate gradient and back-propagate to calculate the new weights\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Find probabilities on the test set\n",
    "    X_test = np.array(test[test.columns[0:num_features]])\n",
    "    test_tensor = torch.FloatTensor(X_test)\n",
    "\n",
    "    probs = []\n",
    "    for t in test_tensor:\n",
    "        probs.append(model.predict(t))\n",
    "    probs = list([float(t[0]) for t in probs])\n",
    "    \n",
    "    return losses, probs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def plot_average_loss_and_auc_per_layer_size(losses_list, probs_list, test_labels_list, plot_title_prefix):\n",
    "    # Figure out average loss and average AUC for each layer size\n",
    "    i = 0\n",
    "\n",
    "    layer_to_losses = {}\n",
    "    layer_to_average_losses = {}\n",
    "    layer_to_indiv_probs = defaultdict(lambda:[])\n",
    "    layer_to_probs = {}\n",
    "    layer_to_average_probs = {}\n",
    "    layer_to_test_labels = defaultdict(lambda:[])\n",
    "\n",
    "    for split_seed in split_seeds:\n",
    "        for hidden_layer_size in hidden_layer_sizes:\n",
    "            next_loss = losses_list[i]\n",
    "            next_probs = probs_list[i]\n",
    "            next_test_labels = test_labels_list[i]\n",
    "\n",
    "            # thin out the losses by only keeping every 1000th entry\n",
    "            thin_loss = [next_loss[j] for j,l in enumerate(next_loss) if j % 1000 == 0]\n",
    "\n",
    "            # Keep running sum of the losses and probabilities at each epoch \n",
    "            if hidden_layer_size in layer_to_losses:\n",
    "                addition = [thin_loss[j] + v for j,v in enumerate(layer_to_losses[hidden_layer_size])]\n",
    "                layer_to_losses[hidden_layer_size] = addition\n",
    "            else:\n",
    "                layer_to_losses[hidden_layer_size] = thin_loss\n",
    "\n",
    "            if hidden_layer_size in layer_to_probs:\n",
    "                addition = [next_probs[j] + v for j,v in enumerate(layer_to_probs[hidden_layer_size])]\n",
    "                layer_to_probs[hidden_layer_size] = addition\n",
    "            else:\n",
    "                layer_to_probs[hidden_layer_size] = next_probs\n",
    "\n",
    "            layer_to_indiv_probs[hidden_layer_size].append(next_probs)\n",
    "            layer_to_test_labels[hidden_layer_size].append(next_test_labels)\n",
    "\n",
    "            i = i + 1\n",
    "\n",
    "    # Now divide by the number of epochs to get the average of the loss/probs at each epoch for each hidden layer size\n",
    "    for hidden_layer_size, losses_per_size in layer_to_losses.items():\n",
    "        layer_to_average_losses[hidden_layer_size] = [l/len(split_seeds) for l in losses_per_size]\n",
    "\n",
    "    for hidden_layer_size, probs_per_size in layer_to_probs.items():\n",
    "        layer_to_average_probs[hidden_layer_size] = [l/len(split_seeds) for l in probs_per_size]\n",
    "\n",
    "    # Plot average losses with various hidden layer sizes\n",
    "    plt.figure(figsize=(14,8))\n",
    "    for k,v in layer_to_average_losses.items():\n",
    "        plt.plot(v)\n",
    "    plt.legend(['{} nodes'.format(k) for k in layer_to_average_losses.keys()])\n",
    "    plt.title('{}: Average loss with various hidden layer sizes'.format(plot_title_prefix))\n",
    "    plt.xlabel('Epochs (thousands)')\n",
    "    plt.ylabel('Cross-entropy loss')\n",
    "\n",
    "    layer_to_roc_aucs = defaultdict(lambda:[])\n",
    "    for layer_size,v in layer_to_indiv_probs.items():\n",
    "        test_labels = layer_to_test_labels.get(layer_size)\n",
    "\n",
    "        for j, probability in enumerate(v):\n",
    "            auc = roc_auc_score(test_labels[j], probability)\n",
    "            layer_to_roc_aucs[layer_size].append(auc)\n",
    "\n",
    "\n",
    "    import seaborn as sns, operator as op\n",
    "\n",
    "    plt.figure(figsize=(14,8))\n",
    "    # sort keys and values together\n",
    "    sorted_keys, sorted_vals = list(layer_to_roc_aucs.keys()), list(layer_to_roc_aucs.values())\n",
    "\n",
    "    # almost verbatim from question\n",
    "    sns.set(context='notebook', style='whitegrid')\n",
    "    sns.boxplot(data=sorted_vals, width=.18)\n",
    "    sns.swarmplot(data=sorted_vals, size=6, edgecolor=\"black\", linewidth=.9)\n",
    "\n",
    "    # category labels\n",
    "    plt.xticks(plt.xticks()[0], sorted_keys)\n",
    "    plt.title('{}: ROC AUC at replicates of various hidden layer sizes'.format(plot_title_prefix))\n",
    "    plt.ylabel('ROC AUC')\n",
    "    plt.xlabel('Number of nodes in hidden layer')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the model using just the first 750 genes as a baseline to compare the preselected 750 breast cancer-associated genes against"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables used in all the different runs...\n",
    "hidden_layer_sizes = [2, 4, 8, 16]\n",
    "learning_rate = 0.0001\n",
    "epochs = 100000\n",
    "fraction_test = 0.33\n",
    "split_seeds = range(1,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using only the first 750 genes...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(64, 64, 64, 32, 32)"
      ]
     },
     "execution_count": 730,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data, y_data, train_labels, test, test_labels = split_dataset(original_dataset, fraction_test, split_seed, 750)\n",
    "len(x_data), len(y_data), len(train_labels), len(test), len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from random import sample \n",
    "\n",
    "# Variables\n",
    "num_genes = 750\n",
    "\n",
    "test = None\n",
    "all_losses = []\n",
    "all_probs = []\n",
    "all_test_labels = []\n",
    "\n",
    "for split_seed in split_seeds:\n",
    "    for hidden_layer_size in hidden_layer_sizes:\n",
    "        print('Next run: split seed: {}, hidden layer size: {}...'.format(split_seed, hidden_layer_size))\n",
    "        num_features = num_genes\n",
    "        x_data, y_data, train_labels, test, test_labels = split_dataset(original_dataset, fraction_test, split_seed, num_features)\n",
    "        losses, probs = run_model(x_data, y_data, test, num_features, hidden_layer_size, learning_rate, epochs)\n",
    "        all_losses.append(losses)\n",
    "        all_probs.append(probs)\n",
    "        print('test labels length', len(test_labels))\n",
    "        all_test_labels.append(test_labels)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_average_loss_and_auc_per_layer_size(all_losses,\n",
    "                                         all_probs, \n",
    "                                         all_test_labels, \n",
    "                                         'Random subset of 750 genes (first 750)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now do it with just the 750 pre-selected genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750\n",
      "Using only the first 750 genes...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(64, 64, 64, 32, 32)"
      ]
     },
     "execution_count": 734,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(ensgs_subset))\n",
    "preselected_dataset = original_dataset[ensgs_subset+['output']]\n",
    "len(preselected_dataset.columns)\n",
    "\n",
    "x_data, y_data, train_labels, test, test_labels = split_dataset(preselected_dataset, fraction_test, split_seed, 750)\n",
    "len(x_data), len(y_data), len(train_labels), len(test), len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next run: split seed: 1, hidden layer size: 2...\n",
      "Using only the first 750 genes...\n",
      "epoch: 0, loss: 0.6907444596290588\n",
      "epoch: 10000, loss: 0.22866187989711761\n",
      "epoch: 20000, loss: 0.13029073178768158\n",
      "epoch: 30000, loss: 0.08345133811235428\n",
      "epoch: 40000, loss: 0.05694384500384331\n",
      "epoch: 50000, loss: 0.040585171431303024\n",
      "epoch: 60000, loss: 0.029980510473251343\n",
      "epoch: 70000, loss: 0.022349335253238678\n",
      "epoch: 80000, loss: 0.01657821238040924\n",
      "epoch: 90000, loss: 0.012230243533849716\n",
      "test labels length 32\n",
      "Next run: split seed: 1, hidden layer size: 4...\n",
      "Using only the first 750 genes...\n",
      "epoch: 0, loss: 0.9729025959968567\n",
      "epoch: 10000, loss: 0.3856033682823181\n",
      "epoch: 20000, loss: 0.222087562084198\n",
      "epoch: 30000, loss: 0.09735608845949173\n",
      "epoch: 40000, loss: 0.0829474925994873\n",
      "epoch: 50000, loss: 0.07746990770101547\n",
      "epoch: 60000, loss: 0.07593949139118195\n",
      "epoch: 70000, loss: 0.07533413916826248\n",
      "epoch: 80000, loss: 0.07509239763021469\n",
      "epoch: 90000, loss: 0.07499512284994125\n",
      "test labels length 32\n",
      "Next run: split seed: 1, hidden layer size: 8...\n",
      "Using only the first 750 genes...\n",
      "epoch: 0, loss: 0.6468116044998169\n",
      "epoch: 10000, loss: 0.034067701548337936\n",
      "epoch: 20000, loss: 0.003404878545552492\n",
      "epoch: 30000, loss: 0.0005111529608257115\n",
      "epoch: 40000, loss: 8.809760038275272e-05\n",
      "epoch: 50000, loss: 1.6349757061107084e-05\n",
      "epoch: 60000, loss: 3.139576165267499e-06\n",
      "epoch: 70000, loss: 6.258523512769898e-07\n",
      "epoch: 80000, loss: 1.3969857093343307e-07\n",
      "epoch: 90000, loss: 4.097821104664945e-08\n",
      "test labels length 32\n",
      "Next run: split seed: 1, hidden layer size: 16...\n",
      "Using only the first 750 genes...\n",
      "epoch: 0, loss: 0.7080796957015991\n",
      "epoch: 10000, loss: 0.010011681355535984\n",
      "epoch: 20000, loss: 0.0004113371833227575\n",
      "epoch: 30000, loss: 1.7444725017412566e-05\n",
      "epoch: 40000, loss: 1.002112867354299e-06\n",
      "epoch: 50000, loss: 6.798660479034879e-08\n",
      "epoch: 60000, loss: 1.0244550097127103e-08\n",
      "epoch: 70000, loss: 3.725290298461914e-09\n",
      "epoch: 80000, loss: 2.7939677238464355e-09\n",
      "epoch: 90000, loss: 9.313225746154785e-10\n",
      "test labels length 32\n",
      "Next run: split seed: 2, hidden layer size: 2...\n",
      "Using only the first 750 genes...\n",
      "epoch: 0, loss: 0.6277235150337219\n",
      "epoch: 10000, loss: 0.35681378841400146\n",
      "epoch: 20000, loss: 0.16178971529006958\n",
      "epoch: 30000, loss: 0.07534252852201462\n",
      "epoch: 40000, loss: 0.03754611685872078\n",
      "epoch: 50000, loss: 0.020701957866549492\n",
      "epoch: 60000, loss: 0.012350603938102722\n",
      "epoch: 70000, loss: 0.007640301715582609\n",
      "epoch: 80000, loss: 0.0047797332517802715\n",
      "epoch: 90000, loss: 0.0029929194133728743\n",
      "test labels length 32\n",
      "Next run: split seed: 2, hidden layer size: 4...\n",
      "Using only the first 750 genes...\n",
      "epoch: 0, loss: 0.6634590029716492\n",
      "epoch: 10000, loss: 0.27347859740257263\n",
      "epoch: 20000, loss: 0.07097136229276657\n",
      "epoch: 30000, loss: 0.029621770605444908\n",
      "epoch: 40000, loss: 0.013723598793148994\n",
      "epoch: 50000, loss: 0.007100310176610947\n"
     ]
    }
   ],
   "source": [
    "# Variables\n",
    "num_genes = len(ensgs_subset)\n",
    "\n",
    "\n",
    "all_preselected_losses = []\n",
    "all_preselected_probs = []\n",
    "all_preselected_test_labels = []\n",
    "\n",
    "\n",
    "for split_seed in split_seeds:\n",
    "    for hidden_layer_size in hidden_layer_sizes:\n",
    "        print('Next run: split seed: {}, hidden layer size: {}...'.format(split_seed, hidden_layer_size))\n",
    "        num_features = num_genes\n",
    "        x_data, y_data, train_labels, test, test_labels = split_dataset(original_dataset, fraction_test, split_seed, num_features)\n",
    "        losses, probs = run_model(x_data, y_data, test, num_features, hidden_layer_size, learning_rate, epochs)\n",
    "        all_preselected_losses.append(losses)\n",
    "        all_preselected_probs.append(probs)\n",
    "        print('test labels length', len(test_labels))\n",
    "        all_preselected_test_labels.append(test_labels)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "pd.DataFrame([all_losses,\n",
    "              all_probs,\n",
    "              all_preselected_losses, \n",
    "              all_preselected_probs], index=['losses', 'probs', 'preselected_losses', 'preselected_probs'])\\\n",
    ".to_csv('losses_and_probs_first_two_steps.tsv', sep='\\t', header=True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_average_loss_and_auc_per_layer_size(all_preselected_losses,\n",
    "                                         all_preselected_probs, \n",
    "                                         all_preselected_test_labels, \n",
    "                                         'Preselected 750 breast cancer-associated genes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "pd.DataFrame([all_losses,\n",
    "              all_probs,\n",
    "              all_preselected_losses, \n",
    "              all_preselected_probs\n",
    "             ], index=['losses', 'probs', 'preselected_losses', 'preselected_probs', 'high_expression_losses', 'high_expression_probs'])\\\n",
    ".to_csv('losses_and_probs_first_three_steps.tsv', sep='\\t', header=True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gene sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GSEA_KRAS_BREAST_UP_V1_UP = list(pd.read_csv('data/GSEA_KRAS_BREAST_UP_V1_UP', names=['ENSG']).ENSG)\n",
    "GSEA_VANTVEER_BREAST_CANCER_POOR_PROGNOSIS = list(pd.read_csv('data/GSEA_VANTVEER_BREAST_CANCER_POOR_PROGNOSIS', names=['ENSG']).ENSG)\n",
    "Cancer_census_genes = list(pd.read_csv('data/Cancer_census_genes', names=['ENSG']).ENSG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KRAS BREAST UP Gene set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(GSEA_KRAS_BREAST_UP_V1_UP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kras_dataset = original_dataset[[c for c in GSEA_KRAS_BREAST_UP_V1_UP if c in original_dataset.columns] + ['output']]\n",
    "len(kras_dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kras_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "num_genes = len(kras_dataset.columns) - 1\n",
    "\n",
    "\n",
    "all_kras_losses = []\n",
    "all_kras_probs = []\n",
    "all_kras_test_labels = []\n",
    "\n",
    "for split_seed in split_seeds:\n",
    "    for hidden_layer_size in hidden_layer_sizes:\n",
    "        print('Next run: split seed: {}, hidden layer size: {}...'.format(split_seed, hidden_layer_size))\n",
    "        num_features = num_genes\n",
    "        x_data, y_data, train_labels, test, test_labels = split_dataset(kras_dataset, fraction_test, split_seed, num_features)\n",
    "        losses, probs = run_model(x_data, y_data, test, num_features, hidden_layer_size, learning_rate, epochs)\n",
    "        all_kras_losses.append(losses)\n",
    "        all_kras_probs.append(probs)\n",
    "        print('test labels length', len(test_labels))\n",
    "        all_kras_test_labels.append(test_labels)\n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_average_loss_and_auc_per_layer_size(all_kras_losses,\n",
    "                                         all_kras_probs, \n",
    "                                         all_kras_test_labels, \n",
    "                                         '139 genes from GSEA_KRAS_BREAST_UP_V1_UP gene set')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vantveer Gene set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(GSEA_VANTVEER_BREAST_CANCER_POOR_PROGNOSIS))\n",
    "vantveer_dataset = original_dataset[[c for c in GSEA_VANTVEER_BREAST_CANCER_POOR_PROGNOSIS if c in original_dataset.columns] + ['output']]\n",
    "len(vantveer_dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "num_genes = len(vantveer_dataset.columns) - 1\n",
    "\n",
    "\n",
    "all_vantveer_losses = []\n",
    "all_vantveer_probs = []\n",
    "all_vantveer_test_labels = []\n",
    "\n",
    "for split_seed in split_seeds:\n",
    "    for hidden_layer_size in hidden_layer_sizes:\n",
    "        print('Next run: split seed: {}, hidden layer size: {}...'.format(split_seed, hidden_layer_size))\n",
    "        num_features = num_genes\n",
    "        x_data, y_data, train_labels, test, test_labels = split_dataset(vantveer_dataset, fraction_test, split_seed, num_features)\n",
    "        losses, probs = run_model(x_data, y_data, test, num_features, hidden_layer_size, learning_rate, epochs)\n",
    "        all_vantveer_losses.append(losses)\n",
    "        all_vantveer_probs.append(probs)\n",
    "        print('test labels length', len(test_labels))\n",
    "        all_vantveer_test_labels.append(test_labels)\n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_average_loss_and_auc_per_layer_size(all_vantveer_losses,\n",
    "                                         all_vantveer_probs, \n",
    "                                         all_vantveer_test_labels, \n",
    "                                         '60 genes from GSEA_VANTVEER_BREAST_CANCER_POOR_PROGNOSIS gene set')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cancer gene census gene set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(Cancer_census_genes))\n",
    "cgc_dataset = original_dataset[[c for c in Cancer_census_genes if c in original_dataset.columns] + ['output']]\n",
    "len(cgc_dataset.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "num_genes = len(cgc_dataset.columns) - 1\n",
    "\n",
    "all_cgc_losses = []\n",
    "all_cgc_probs = []\n",
    "all_cgc_test_labels = []\n",
    "\n",
    "for split_seed in split_seeds:\n",
    "    for hidden_layer_size in hidden_layer_sizes:\n",
    "        print('Next run: split seed: {}, hidden layer size: {}...'.format(split_seed, hidden_layer_size))\n",
    "        num_features = num_genes\n",
    "        x_data, y_data, train_labels, test, test_labels = split_dataset(cgc_dataset, fraction_test, split_seed, num_features)\n",
    "        losses, probs = run_model(x_data, y_data, test, num_features, hidden_layer_size, learning_rate, epochs)\n",
    "        all_cgc_losses.append(losses)\n",
    "        all_cgc_probs.append(probs)\n",
    "        print('test labels length', len(test_labels))\n",
    "        all_cgc_test_labels.append(test_labels)\n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_average_loss_and_auc_per_layer_size(all_cgc_losses,\n",
    "                                         all_cgc_probs, \n",
    "                                         all_cgc_test_labels, \n",
    "                                         '710 genes from Cancer Gene Census gene set')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "pd.DataFrame([all_losses,\n",
    "              all_probs,\n",
    "              all_preselected_losses, \n",
    "              all_preselected_probs,\n",
    "              all_kras_losses,\n",
    "              all_kras_probs\n",
    "             ], index=['losses', 'probs', \n",
    "                                             'preselected_losses', 'preselected_probs',\n",
    "                                             'kras_losses', 'kras_probs'\n",
    "                                            ])\\\n",
    ".to_csv('losses_and_probs_saved.tsv', sep='\\t', header=True)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
